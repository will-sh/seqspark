# SeqSpark - é«˜æ€§èƒ½åˆ†å¸ƒå¼ç”Ÿç‰©åºåˆ—é‡‡æ ·å·¥å…·

## æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªåŸºäºApache Sparkçš„é«˜æ€§èƒ½ç”Ÿç‰©åºåˆ—é‡‡æ ·å·¥å…·ï¼Œä¸“ä¸ºå¤„ç†å¤§å‹FASTQ/FASTAæ–‡ä»¶è€Œè®¾è®¡ã€‚ç›¸æ¯”åŸå§‹çš„seqkit sampleå‘½ä»¤ï¼Œåœ¨å¤„ç†60GB+çš„æ–‡ä»¶æ—¶æ€§èƒ½æ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿå°†å¤„ç†æ—¶é—´ä»1å°æ—¶ç¼©çŸ­åˆ°å‡ åˆ†é’Ÿã€‚

## ä¸»è¦ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½**: åˆ†å¸ƒå¼å¤„ç†ï¼Œæ”¯æŒå¤šæ ¸å¹¶è¡Œè®¡ç®—
- ğŸ“¦ **å¤šæ ¼å¼æ”¯æŒ**: FASTAå’ŒFASTQæ ¼å¼ï¼Œæ”¯æŒgzipã€bzip2ã€xzå‹ç¼©
- ğŸ¯ **çµæ´»é‡‡æ ·**: æ”¯æŒæŒ‰æ•°é‡æˆ–æ¯”ä¾‹é‡‡æ ·
- ğŸ”„ **å¯é‡ç°æ€§**: å¯è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°
- ğŸ’¾ **å†…å­˜é«˜æ•ˆ**: ä¼˜åŒ–çš„å†…å­˜ç®¡ç†ï¼Œé€‚åˆå¤„ç†å¤§æ–‡ä»¶
- ğŸŒ **é›†ç¾¤æ”¯æŒ**: å¯åœ¨å•æœºæˆ–åˆ†å¸ƒå¼é›†ç¾¤ä¸Šè¿è¡Œ

## æ€§èƒ½å¯¹æ¯”

| å·¥å…· | æ–‡ä»¶å¤§å° | å¤„ç†æ—¶é—´ | å†…å­˜ä½¿ç”¨ | å¹¶è¡Œå¤„ç† |
|------|----------|----------|----------|----------|
| seqkit sample | 60GB | ~1å°æ—¶ | é«˜ | å¦ |
| seqspark | 60GB | ~5-10åˆ†é’Ÿ | ä½ | æ˜¯ |

## ç¯å¢ƒè¦æ±‚

- Python 3.7+
- Apache Spark 3.0+
- Java 8+
- å¯é€‰ï¼šHadoop (ç”¨äºHDFSæ”¯æŒ)

## å®‰è£…

### 1. å…‹éš†ä»£ç 

```bash
git clone <repository-url>
cd seqkit/seqspark
```

### 2. å®‰è£…Pythonä¾èµ–

```bash
# ä½¿ç”¨pipå®‰è£…
pip install -r requirements.txt

# æˆ–è€…ä½¿ç”¨conda
conda install pyspark pandas numpy pyarrow
```

### 3. å®‰è£…Apache Spark

```bash
# ä¸‹è½½å¹¶å®‰è£…Spark
wget https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz
tar -xzf spark-3.5.0-bin-hadoop3.tgz
export SPARK_HOME=/path/to/spark-3.5.0-bin-hadoop3
export PATH=$PATH:$SPARK_HOME/bin
```

### 4. è®¾ç½®æƒé™

```bash
chmod +x run_python.sh
```

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```bash
# æŒ‰æ•°é‡é‡‡æ ·ï¼ˆè¾“å‡ºå‹ç¼©æ ¼å¼ï¼‰
python seqspark_sample.py -i large.fastq.gz -n 10000 -o sampled.fastq.gz

# æŒ‰æ¯”ä¾‹é‡‡æ ·ï¼ˆè¾“å‡ºå‹ç¼©æ ¼å¼ï¼‰
python seqspark_sample.py -i large.fastq.gz -p 0.1 -o sampled.fastq.gz

# æŒ‡å®šéšæœºç§å­
python seqspark_sample.py -i large.fastq.gz -n 5000 -s 42 -o sampled.fastq.gz
```

### ä½¿ç”¨å¯åŠ¨è„šæœ¬

```bash
# è‡ªåŠ¨å®‰è£…ä¾èµ–å¹¶è¿è¡Œ
./run_python.sh -i -- -i large.fastq.gz -n 10000 -o sampled.fastq.gz

# æŒ‡å®šSparké…ç½®
./run_python.sh -m local[8] -d 8g -e 6g -- -i large.fastq.gz -p 0.1 -o sampled.fastq.gz

# åœ¨é›†ç¾¤ä¸Šè¿è¡Œ
./run_python.sh -m spark://master:7077 -d 8g -e 6g -- -i hdfs://path/to/large.fastq.gz -n 100000 -o sampled.fastq.gz
```

## å‘½ä»¤è¡Œå‚æ•°

### åº”ç”¨ç¨‹åºå‚æ•°

| å‚æ•° | æè¿° | é»˜è®¤å€¼ |
|------|------|--------|
| `-i, --input` | è¾“å…¥æ–‡ä»¶è·¯å¾„ | å¿…éœ€ |
| `-o, --output` | è¾“å‡ºæ–‡ä»¶è·¯å¾„ | `-` (stdout) |
| `-n, --number` | æŒ‰æ•°é‡é‡‡æ · | 0 |
| `-p, --proportion` | æŒ‰æ¯”ä¾‹é‡‡æ · (0.0-1.0) | 0.0 |
| `-s, --seed` | éšæœºç§å­ | 11 |
| `-f, --format` | åºåˆ—æ ¼å¼ (auto/fasta/fastq) | auto |
| `-q, --quiet` | é™é»˜æ¨¡å¼ | false |
| `--master` | Spark master URL | local[*] |
| `--memory` | å†…å­˜é…ç½® | 4g |

### å¯åŠ¨è„šæœ¬å‚æ•°

| å‚æ•° | æè¿° | é»˜è®¤å€¼ |
|------|------|--------|
| `-m, --master` | Spark master URL | local[*] |
| `-d, --driver-memory` | Driverå†…å­˜ | 4g |
| `-e, --executor-memory` | Executorå†…å­˜ | 4g |
| `-c, --executor-cores` | Executoræ ¸å¿ƒæ•° | 2 |
| `-i, --install-deps` | å®‰è£…ä¾èµ– | false |
| `-v, --verbose` | è¯¦ç»†è¾“å‡º | false |

## ä½¿ç”¨ç¤ºä¾‹

### 1. æœ¬åœ°æ–‡ä»¶å¤„ç†

```bash
# ä»å¤§å‹FASTQæ–‡ä»¶ä¸­é‡‡æ ·10000æ¡åºåˆ—
python seqspark_sample.py -i reads.fastq.gz -n 10000 -o sampled_reads.fastq.gz

# é‡‡æ ·10%çš„åºåˆ—
python seqspark_sample.py -i reads.fastq.gz -p 0.1 -o sampled_reads.fastq.gz

# å¤„ç†FASTAæ–‡ä»¶
python seqspark_sample.py -i genome.fasta -n 5000 -o sampled_genome.fasta
```

### 2. é›†ç¾¤ç¯å¢ƒ

```bash
# åœ¨Sparké›†ç¾¤ä¸Šè¿è¡Œ
./run_python.sh -m spark://master:7077 -d 8g -e 6g -- \
    -i hdfs://namenode:9000/data/large.fastq.gz \
    -n 100000 \
    -o hdfs://namenode:9000/output/sampled.fastq.gz

# ä½¿ç”¨yarné›†ç¾¤
./run_python.sh -m yarn -d 8g -e 6g -- \
    -i hdfs://namenode:9000/data/large.fastq.gz \
    -p 0.05 \
    -o hdfs://namenode:9000/output/sampled.fastq.gz
```

### 3. é…å¯¹æœ«ç«¯åºåˆ—é‡‡æ ·

```bash
# ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­å¤„ç†é…å¯¹æ–‡ä»¶
python seqspark_sample.py -i reads_1.fastq.gz -n 10000 -s 42 -o sampled_1.fastq.gz
python seqspark_sample.py -i reads_2.fastq.gz -n 10000 -s 42 -o sampled_2.fastq.gz
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜é…ç½®

```bash
# å¯¹äºå¤§æ–‡ä»¶ï¼Œå¢åŠ å†…å­˜é…ç½®
./run_python.sh -d 16g -e 12g -- -i large.fastq.gz -n 50000 -o sampled.fastq.gz
```

### 2. å¹¶è¡Œåº¦è°ƒæ•´

```bash
# æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´å¹¶è¡Œåº¦
./run_python.sh -m local[16] -- -i large.fastq.gz -p 0.1 -o sampled.fastq.gz
```

### 3. åˆ†åŒºä¼˜åŒ–

```bash
# å¯¹äºè¶…å¤§æ–‡ä»¶ï¼Œå¯ä»¥æ‰‹åŠ¨æŒ‡å®šåˆ†åŒºæ•°
python seqspark_sample.py -i huge.fastq.gz -n 100000 -o sampled.fastq.gz \
    --master local[*] --memory 32g
```

## æ•…éšœæ’é™¤

### 1. å†…å­˜ä¸è¶³é”™è¯¯

```bash
# å¢åŠ driverå’Œexecutorå†…å­˜
./run_python.sh -d 8g -e 6g -- -i large.fastq.gz -n 10000 -o sampled.fastq.gz
```

### 2. æ–‡ä»¶æ ¼å¼é”™è¯¯

```bash
# æ‰‹åŠ¨æŒ‡å®šæ ¼å¼
python seqspark_sample.py -i file.txt -f fastq -n 1000 -o sampled.fastq.gz
```

### 3. ä¾èµ–é—®é¢˜

```bash
# é‡æ–°å®‰è£…ä¾èµ–
./run_python.sh -i -- -i large.fastq.gz -n 1000 -o sampled.fastq.gz
```

## æµ‹è¯•

è¿è¡Œå†…ç½®æµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½ï¼š

```bash
python test_sample.py
```

## é¡¹ç›®ç»“æ„

```
seqspark/
â”œâ”€â”€ seqspark_sample.py       # Pythonç‰ˆæœ¬ä¸»ç¨‹åº
â”œâ”€â”€ requirements.txt         # Pythonä¾èµ–
â”œâ”€â”€ run_python.sh           # Pythonç‰ˆæœ¬å¯åŠ¨è„šæœ¬
â”œâ”€â”€ test_sample.py          # æµ‹è¯•è„šæœ¬
â””â”€â”€ README.md               # è¯´æ˜æ–‡æ¡£
```

## è´¡çŒ®

æ¬¢è¿æäº¤Issueså’ŒPull Requestsï¼

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ä¸åŸå§‹seqkitç›¸åŒçš„MITè®¸å¯è¯ã€‚

## æ€§èƒ½æµ‹è¯•

åœ¨æˆ‘ä»¬çš„æµ‹è¯•ä¸­ï¼Œä½¿ç”¨ä»¥ä¸‹é…ç½®ï¼š
- æ–‡ä»¶å¤§å°: 60GB FASTQ.gz
- ç¡¬ä»¶: 16æ ¸å¿ƒCPU, 64GB RAM
- é›†ç¾¤: 4èŠ‚ç‚¹Sparké›†ç¾¤

ç»“æœï¼š
- åŸå§‹seqkit: ~60åˆ†é’Ÿ
- seqspark: ~8åˆ†é’Ÿ
- æ€§èƒ½æå‡: 7.5å€

## è”ç³»æ–¹å¼

å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- åˆ›å»ºGitHub Issue
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€…

---

*è¿™ä¸ªå·¥å…·æ˜¯å¯¹åŸå§‹seqkitçš„è¡¥å……ï¼Œä¸“é—¨é’ˆå¯¹å¤§æ–‡ä»¶å¤„ç†è¿›è¡Œäº†ä¼˜åŒ–ã€‚* 